/*light info*/
struct LightCamInfo
{
	mat4 lightMat;
	float near;
	float far;
	vec3 lightCamPos;
	vec3 lightViewDir;
};
uniform LightCamInfo lightCamInfos[maxLightNum]; // "maxLightNum" is defined in "phong_vsm.main_fs"

/*shadow map*/
uniform sampler2D shadowMaps[maxLightNum]; // "maxLightNum" is defined in "phong_vsm.main_fs"

/*SAT-VSM related, refer GPUGems3: SummedArea Variance ShadowMaps*/
uniform float varMin; /*minimum variance to reduce numeric inaccuracy(also biasing)*/
uniform float pMin; /*remove range[0, pMin], then rescale pMax from range[pMin, 1] to [0,1]*/
uniform sampler2D SATMaps[maxLightNum]; // "maxLightNum" is defined in "phong_vsm.main_fs"

/*PCSS related, when integrate PCSS into VSM, the kernelSize is using PenumbraSize*/
/*PCSS-percentage closer Soft filtering*/
uniform	int lightSize;
uniform int minPenumbraSize;
uniform int maxPenumbraSize;

/*VSSM related*/
uniform int M; // subdivision M*M
uniform int N; // subdivision N*N


float GetSearchSize(LightCamInfo lightCamInfo)
{
	// search area kernel size is based on light to distance and light size
	vec3 worldPos = (modelMat*vec4(fPos,1.0)).xyz;
	vec3 v = worldPos - lightCamInfo.lightCamPos;
	vec3 proAxis = normalize(lightCamInfo.lightViewDir);
	float linearDepth = dot(v, proAxis);
	float weight = (linearDepth - lightCamInfo.near) / linearDepth;
	weight = clamp(weight, 0.0, 1.0);
	// according to the paper, the size of search region is proportional to distance and lightSize
	// from the PCSS presentation slide Page 14, search size is 0 when being at the receiver plane, 
	// and shadow map is at near plane. We want to know the size when being at the near plane.
	return lightSize*weight; 
}

// receiverDepth: receiver depth, current: uv of current fragement in ShadowMap
float GetBlockerDepth(float receiverDepth, vec2 current, sampler2D shadowMap, vec2 texelSize, float halfSearchSize)
{
	float blockerDepth = 0.0;
	int totalNum = 0;
	for(float i = -halfSearchSize; i <= halfSearchSize; i++)
	{
		for(float j = -halfSearchSize; j <= halfSearchSize; j++)
		{
			float refDepth = texture(shadowMap, current+vec2(i,j)*texelSize).r;
			if(receiverDepth>=refDepth)
			{
				totalNum += 1;
				blockerDepth += refDepth;
			}
		}
	}
	if(totalNum == 0)
		return 1.0; // no blocker found
	else
		return blockerDepth/totalNum;
}

float ComputePenumbraSize(float receiverDepth, float blockerDepth, float lightSize)
{
	float wPenum = (receiverDepth - blockerDepth) * lightSize / blockerDepth; // this is just a weight
	// In fact, (r-b)/b*size --> (r/b-1)*size. --> r/b can be a very large number!
	// Also we can draw the picture when the blocker area is near to area light, the penumbra size will become very large
	// Therefore, clamping penumbra size makes sense.
	return clamp(wPenum, minPenumbraSize, maxPenumbraSize);
}

/*Given a center, half kernel size and its SAT map, return the mean of this kernel area*/
vec2 GetMean(ivec2 texSize, ivec2 center, sampler2D SATMap, int _halfKernelSize)
{
	// [Note] texel space coordinate is inside [0, resolution-1]. 
	ivec2 minCorner = center - ivec2(_halfKernelSize+1);
	ivec2 maxCorner = center + ivec2(_halfKernelSize);
	// don't clamp corner first, because we do need some values which are out of range to compute true sum.
	// those elements out of range will return border value, here it is zero.
	vec4 result4 = texelFetch(SATMap, maxCorner, 0) - texelFetch(SATMap, ivec2(minCorner.x, maxCorner.y), 0) - texelFetch(SATMap, ivec2(maxCorner.x, minCorner.y), 0) + texelFetch(SATMap, minCorner, 0);

	// compute the real number over kernel area, must clamp corner.
	minCorner = clamp(minCorner, ivec2(0), texSize-ivec2(1));
	maxCorner = clamp(maxCorner, ivec2(0), texSize-ivec2(1));
	int totalNum = max(maxCorner.x-minCorner.x, 1) * max(maxCorner.y-minCorner.y, 1);
	vec2 loss = vec2(0.5); // don't forget compensate this loss
	vec2 menOutput = result4.xy/totalNum + loss; //totalLoss = loss * totalNum-> its mean loss is loss

	return menOutput;
}

struct TexelInfo
{
	ivec2 lb, lt, rb, rt; /*four texel coordinates at four corners over a rectangle area*/
	vec2 weight;
};

/*return four texels which are surrounding the uvCoord. We can use these four texels to do bilinear interpolation*/
TexelInfo GetFourTexels(ivec2 texSize, vec2 texelSize, vec2 uvCoord)
{
	float weightX, weightY;
	int minX, maxX, minY, maxY; // in texel space [0, resolution-1]
	ivec2 texelNum = ivec2(uvCoord/texelSize); // check how many completed texels it has already contained.
	vec2 offset = uvCoord - texelNum*texelSize;
	vec2 halfTexelSize = 0.5 * texelSize;
	
	// X direction
	if(offset.x < halfTexelSize.x)
	{
		minX = texelNum.x - 1;
		weightX = (halfTexelSize.x+offset.x)/(texelSize.x);
	}
	else
	{
		minX = texelNum.x;
		weightX = (offset.x-halfTexelSize.x)/(texelSize.x);
	}
	maxX = minX + 1;

	// clamp the range, must execute after computation. Don't do it above
	minX = clamp(minX, 0, texSize.x-1);
	maxX = clamp(maxX, 0, texSize.x-1);

	// Y direction
	if(offset.y < halfTexelSize.y)
	{
		minY = texelNum.y - 1;
		weightY = (halfTexelSize.y+offset.y)/(texelSize.y);
	}
	else
	{
		minY = texelNum.y;
		weightY = (offset.y-halfTexelSize.y)/(texelSize.y);
	}
	maxY = minY + 1;

	minY = clamp(minY, 0, texSize.y-1);
	maxY = clamp(maxY, 0, texSize.y-1);

	TexelInfo texelInfo;
	texelInfo.lb = ivec2(minX, minY);
	texelInfo.lt = ivec2(minX, maxY);
	texelInfo.rb = ivec2(maxX, minY);
	texelInfo.rt = ivec2(maxX, maxY);
	texelInfo.weight = vec2(weightX, weightY);

	return texelInfo;
}

/*return bilinear interpolation*/
vec2 GetBilinearValue(vec2 lb, vec2 lt, vec2 rb, vec2 rt, vec2 weight)
{
	vec2 res1 = mix(lb, rb, weight[0]); // bottom horizontal interpolation
	vec2 res2 = mix(lt, rt, weight[0]); // top horizontal interpolation
	return mix(res1, res2, weight[1]); // from bottom to top, vertical interpolation
}

/*average the depth/depth_square over kernel*/
vec2 GetMoment(vec2 uvCoord, sampler2D SATMap, int _halfKernelSize)
{
	float M1 = 0.0, M2 = 0.0;
	
	/*moment is vec2(E(x), E(x^2)), that's why we need a kernel to filter an area to get mean*/
	/*filtering*/
	// [Note] texel space coordinate is inside [0, resolution-1]. 
	ivec2 texSize = textureSize(SATMap, 0);
	vec2 texelSize = 1.0/texSize;

	/*Bilinear interpolation is better*/
	TexelInfo texelInfo = GetFourTexels(texSize, texelSize, uvCoord);
	vec2 lbMean = GetMean(texSize, texelInfo.lb, SATMap, _halfKernelSize);
	vec2 ltMean = GetMean(texSize, texelInfo.lt, SATMap, _halfKernelSize);
	vec2 rbMean = GetMean(texSize, texelInfo.rb, SATMap, _halfKernelSize);
	vec2 rtMean = GetMean(texSize, texelInfo.rt, SATMap, _halfKernelSize);

	/*We need to do linear interpolation by ourselves. SAT can not use texture() to get value.*/
	/*SAT is texel based, can not be used to interpolation.*/
	vec2 biliRes = GetBilinearValue(lbMean, ltMean, rbMean, rtMean, texelInfo.weight);
	M1 = biliRes.x;
	M2 = biliRes.y;

	return vec2(M1, M2);
}

float ComputeChebychevUpperBound(float t, vec2 moment)
{
	if(t<=moment.x)
		return 1.0;

	/*moment is vec2(E(x), E(x^2))*/
	float differ = t - moment.x; /*depth minus mean*/
	/*using this math formula will get some variance less than zero because of float-precision or other reason*/
	float variance = max(moment.y - moment.x*moment.x, 0); /*variance square*/
	variance = max(variance, varMin);
	return variance / (variance + differ*differ);
}

float GetBlockerDepthSubdivision(float t, float wi, vec3 shadowCoord, sampler2D SATMap, sampler2D shadowMap, vec2 texelSize)
{
	// subdivide filter kernel wi, each sub-kernel check whether it is "non-planarity" kernel
	// if not, using the formula to get blocker-depth for this kernel, 
	// if yes, PCF to get blocker-depth
	// each sub-kernel multiply its kernel size then finally divided by the wi
	// using N*N grid to subdivide this kernel size wi
	// [TODO] issue, kernel can not be divided perfectly, especially when using SAT, it requires (int) kernel size
	float wiHalf = wi / 2;
	float wiSub = wi / N;
	float wiSubHalf = wiSub / 2;
	vec2 lbCoord = shadowCoord.xy - vec2(wiHalf) + vec2(wiSubHalf) ; // left-bottom sub-kernel center coordinate
	
	// below it will compute two groups: normal case and "non-planarity" case
	int normalTotalSize = 0;
	int nonplanrTotalSize = 0;
	
	vec2 sumMoment = vec2(0); // store for normal case

	float d2 = 0; // non-planarity blocker depth

	for(int i=0; i<N; i++)
	{
		for(int j=0; j<N; j++)
		{
			int subHalfSize = int(ceil(wiSubHalf));
			vec2 curCoord = lbCoord + ivec2(i, j)*vec2(wiSub);
			vec2 moment = GetMoment(curCoord, SATMap, subHalfSize);
			float zAvg = moment.x; // depth average from this sub kernel
			int subKernelSize = (subHalfSize*2)*(subHalfSize*2); // of course it is not this size, just take it simple here
			//[TODO] maybe above it is not good
		 	
		 	if(t <= zAvg)
		 	{
		 		// non-planarity case, using M*M with PCF to get blocker depth
				float blockerDepth = GetBlockerDepth(t, curCoord, shadowMap, texelSize, M/2.0);
		 		d2 += blockerDepth;
		 		nonplanrTotalSize += subKernelSize;
		 	}
		 	else
		 	{
		 		// normal case
		 		sumMoment += (moment * subKernelSize); // after this loop, it will divided by the normal size.
		 		normalTotalSize += subKernelSize;
		 	}
		}
	}
	
	// get d1
	vec2 normalMoment = sumMoment / normalTotalSize; // moment for the normal group
	float pMax = ComputeChebychevUpperBound(t, normalMoment);
	pMax = (pMax-pMin)/(1.0-pMin); /*linear interpolation-map the [pMin, 1] to [0, 1]*/
	pMax = clamp(pMax, 0, 1);
	float d1 = (normalMoment.x - pMax*t)/(1 - pMax);

	// d2 is computed from above

	int totalSize = normalTotalSize + nonplanrTotalSize;
	float d = d1*normalTotalSize + d2*nonplanrTotalSize;
	d /= totalSize;
	return d;
}


float ComputeLightRatio(LightCamInfo lightCamInfo, sampler2D shadowMap, sampler2D SATMap)
{
	/*ComputeLightRatio: lightRatio is inside [0, 1]*/
	vec4 clipCoord = lightCamInfo.lightMat*modelMat*vec4(fPos,1.0); /*clip space*/
	vec3 ndcCoord = clipCoord.xyz / clipCoord.w; /*ndc space: [-1,1]^3*/ 
	vec3 shadowCoord = (ndcCoord+1)/2.0; /*map [-1,1]^3 to [0,1]^3*/
	/*note this frageDepth is not clipped. We need to check it by ourselves if neccessary.*/  
	/*we can just set no-shadow for those vertices which are outside of the light view frustum*/
	//float fragDepth = shadowCoord.z; // this is projected depth, don't use it

	/*[Important] for avoid projected z-depth precision issue, using linear depth not projected depth*/
	/*we know z values near to far plane will be hard to compare*/
	vec3 worldPos = (modelMat*vec4(fPos,1.0)).xyz;
	vec3 v = worldPos - lightCamInfo.lightCamPos;
	vec3 proAxis = normalize(lightCamInfo.lightViewDir);
	float linearDepth = dot(v, proAxis);
	linearDepth = (linearDepth - lightCamInfo.near) / (lightCamInfo.far - lightCamInfo.near);
	float fragDepth = linearDepth;


	// The core idea is to fix the issue when using zAvg compares with current fragment depth
	// if kernel is not planar (perpendicular to light view direction), there are maybe some fragment are closer than 
	// current fragement(occluders) when current depth is less than zAvg.
	// Put it simple and short: misclassify fragment's light ratio.
	// Example: it is not fully-lit but it is classified as fully-lit.

	/*---------------------- L7 ----------------------*/ 
	// compute blocker search area size "wi"
	float wi = GetSearchSize(lightCamInfo); /*initial kernel size wi*/

	// [TODO]
	// I don't have time to implement HSM, I only focus "non-planarity" issue and also use variance condition
	// because wiHalf is decided by light size. If we just set a not large light size, I think it is acceptable.
	float wiHalf = wi / 2;
	vec2 texelSize = 1.0/textureSize(shadowMap, 0);

	/*---------------------- L11 ----------------------*/ 
	vec2 moment = GetMoment(shadowCoord.xy, SATMap, int(wiHalf));

	float zAvg = moment.x; // mean depth from kernel
	float varAbs = abs(moment.y - moment.x*moment.x); // if this absolute variance is big enough, then non-planarity

	ivec2 texSize = textureSize(SATMap, 0);

	// check wi is "non-planarity" kernel
	float zOcc;
	float zUnocc = fragDepth; // used their assumption

	if(fragDepth <= zAvg && varAbs > 0.00001)
	{
		// possibly have non-planarity cases
		zOcc = GetBlockerDepthSubdivision(fragDepth, wi, shadowCoord, SATMap, shadowMap, texelSize);
	}
	else
	{
		float pMax = ComputeChebychevUpperBound(fragDepth, moment);
		pMax = (pMax-pMin)/(1.0-pMin); /*linear interpolation-map the [pMin, 1] to [0, 1]*/
		pMax = clamp(pMax, 0, 1);
		zOcc = (zAvg - pMax*zUnocc)/(1 - pMax);
	}

	/*---------------------- L16 ----------------------*/ 

	//issue: zOcc = (zAvg - pMax*zUnocc)/(1 - pMax); this formula will return negative value.
	// use below code to show it
	//if(zOcc < 0)
		//discard;
	zOcc = max(zOcc, 0.00001);

	float penumBraSize = ComputePenumbraSize(fragDepth, zOcc, lightSize);
	vec2 finalMoment = GetMoment(shadowCoord.xy, SATMap, int(penumBraSize / 2.0));
	float pMaxFinal = ComputeChebychevUpperBound(fragDepth, finalMoment);
	pMaxFinal = (pMaxFinal-pMin)/(1.0-pMin); /*linear interpolation-map the [pMin, 1] to [0, 1]*/
	pMaxFinal = clamp(pMaxFinal, 0, 1);

	return pMaxFinal;
}